---
title: "Calculating metrics from streamflow data"
author: "Jian Yen"
date: "26/10/2021"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Calculating metrics from streamflow data}
  %\usepackage[utf8]{inputenc}
---

```{r setup, include = FALSE}
# display code by default
knitr::opts_chunk$set(echo = TRUE)
```

## Getting started

Start by loading the `aae.hydro` package and downloading some data to work with.

```{r getting-started}
# load some packages we'll use
library(aae.hydro)
library(lubridate)
library(dplyr)
library(tidyr)

# get some data to work with in the vignette
flow_data <- fetch_hydro(
  sites = c("405232", "406201", "406202", "406276", "406278"),
  start = "2004-01-01",
  end = "2020-04-21",
  variables = c("flow", "temp", "depth")
)

# and convert it to a wider format
flow_wide <- flow_data %>% pivot_wider(
  id_cols = c(date_formatted, site_name, site_code),
  names_from = variable_name,
  values_from = c(value, units, quality_code)
)
```

## Summarising flow data

Once we have access to flow data, the next challenge is to convert flow data into relevant metrics or summary statistics. The `aae.hydro` package aims to make this easy with a single function: `calculate`. The `calculate` function takes data on any variable, along with dates of observations, and summarises this at a resolution of your choosing. Some examples might make this clearer.

```{r calculate-basic-examples}
# first, pull out the data for a single site (Goulburn @ McCoys Bridge)
#    (we can avoid this step, see *Working with many variables or systems*, below)
flow_405232 <- flow_wide %>% filter(site_code == "405232")

# calculate the median spring flow (months 9-11) for 2009-2015 at this site
#    - this function takes in the daily discharge, the dates, a function
#        ("survey", here) that defines the resolution of our flow metric,
#        and a function ("fun") that tells calculate how to summarise the
#        data
spring_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = survey(season = 9:11, lag = 0, subset = 2009:2015),
  fun = median,
  na.rm = TRUE
)
```

The output of this is a `data.frame` with dates (years, here) and the calculated flow metric.

```{r print-flow-example, echo = FALSE}
spring_flow %>% as_tibble
```

The `resolution` term does the heavy lifting in defining the chosen flow metric. The term used above (`survey(season = 9:11, lag = 0, subset = 2009:2015)`) tells calculate that we want to focus on unlagged flow data for survey years (more on this below), for the years 2009 to 2015. It is straightforward to change the `season` term to capture some other season (e.g. winter, `season = 6:8`) or any set of months (e.g. late-spring/early summer, `season = 10:12`).

There are several other resolutions available. If these aren't good enough, you can even define your own resolution function.

```{r resolution-examples}
# calculate the median weekly flow from 2004-2006
weekly_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = weekly(subset = 2004:2006),
  fun = median,
  na.rm = TRUE
)

# calculate the median monthly flow from 2005-2011
monthly_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = monthly(subset = 2005:2011),
  fun = median,
  na.rm = TRUE
)

# calculate the median annual flow from 2009-2018
annual_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = annual(subset = 2009:2018),
  fun = median,
  na.rm = TRUE
)

# calculate the overall median flow from 2004-2020
baseline_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = baseline(subset = 2004:2006),
  fun = median,
  na.rm = TRUE
)
```

The general idea behind the `calculate` function is to avoid defining many functions to calculate very specific metrics. Here, with a single function, we can easily shift from weekly to monthly to annual metrics, from median to maximum values, and from spring to summer. We can also add lags in these calculations.

```{r more-calculate-examples}
# calculate the maximum annual flow from 2005-2019
annual_max <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = annual(subset = 2005:2019),
  fun = max,
  na.rm = TRUE
)

# or the minimum
annual_min <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = annual(subset = 2005:2019),
  fun = min,
  na.rm = TRUE
)

# there's even some custom functions
# including one for rolling ranges
flow_variability <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = annual(subset = 2005:2019),
  fun = rolling_range,
  lag = 3
)

# and one to count days below a threshold (the baseline 10th percentile, here)
longterm_q10 <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = baseline(subset = 2004:2020),
  fun = quantile,
  p = 0.1
)
low_flow_days <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = annual(subset = 2005:2019),
  fun = days_below,
  threshold = longterm_q10
)

# it's easy to add lags, which can be especially useful for short-term flows
#   (e.g. average weekly flow one week prior to sampling)
lagged_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = weekly(subset = 2005:2006, lag = 1),
  fun = median
)

# the lag defaults to a semi-logical timeframe (weeks for weekly, years for annual)
#   but you can also specify this explicitly if needed
same_lagged_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = weekly(subset = 2005:2006, lag = days(7)),
  fun = median
)
```

We're often comparing flow among rivers. A straight metric (e.g., the maximum) might not be useful or comparable in several rivers of different size or structure. The `calculate` function addresses this with a standardise argument, which provides a flexible way to standardise your calculated metric by some other aspect of the flow (e.g. the long-term median flow). The standardise argument looks very similar to the resolution argument.

```{r calculate-standardise-examples}
# calculate median spring flow from 2009-2015, but standardise it by the long-term 
#   median flow from 2004-2020
spring_flow_standardised <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = survey(season = 9:11, lag = 0, subset = 2009:2015),
  standardise = by_median(subset = 2004:2020, season = 1:12, na.rm = TRUE),
  na.rm = TRUE
)
```

This might look like a fair bit of typing, but the `standardise` argument has some defaults built-in, so you don't need to type everything out unless you want to do something different. The current defaults are `subset = all_available_years`, `fun = median` and `season = 1:12`.

### An aside on the `survey` resolution

The `survey` resolution is designed to summarise flow data across a two-year period. The motivation for this was flow metrics to line up with autumn surveys, where fish catches were hypothesised to be influenced by flow events in the year before and the year of a survey. The season argument to `survey` ranges from 1 to 24, with 1 being January in the year prior to a survey and 24 being December in the year of a survey (probably after the survey occurred).

For many variables, the "lag" argument will achieve the same result. But `survey` is included to account for a couple of situations that occur relatively frequently:

```{r calculate-survey-examples}
# summer starting the year before a survey and ending in the survey year
summer_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = survey(season = 12:14, lag = 0, subset = 2009:2015),
  fun = median,
  na.rm = TRUE
)

# the 12 months prior to a May survey
summer_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = survey(season = 5:16, lag = 0, subset = 2009:2015),
  fun = median,
  na.rm = TRUE
)
```

If you look at the output from this function, you might notice that the date doesn't always match the year in which a flow event occurred. In all cases, the date will match the *year of survey*, which is not the same as the flow year if season includes any value less than 12 (i.e. any months in the year prior to a survey). Obviously, if you want values entirely within a calendar year, the `survey` resolution will be the same as a lagged `annual` resolution.

```{r compare-survey-and-annual}
# survey resolution for spring in the year prior to a survey
spring_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = survey(season = 9:11, lag = 0, subset = 2009:2015),
  fun = median,
  na.rm = TRUE
)

# annual resolution for this same time period
spring_flow_lagged <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = annual(season = 9:11, lag = 1, subset = 2009:2015),
  fun = median,
  na.rm = TRUE
)
```

## Truncating observations to exclude leading or trailing data points

In some cases, it can be useful to exclude leading or trailing data points from calculations. Examples include calculating metrics following onset of the monsoon season, which may differ from year to year and doesn't align with calendar months, or the exclusion of data points following a field survey because these data points clearly do not contribute to observed survey data. Truncation can be included in the `annual` and `survey` resolutions with option `start` and `end` arguments. Either or both can be provided, depending on whether leading or trailing data points need to be trimmed.

```{r demonstrate-truncation}
# survey resolution for spring in the year prior to a survey
spring_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = survey(season = 9:11, lag = 0, subset = 2009:2015),
  fun = median,
  na.rm = TRUE
)

# simulate some survey dates
nsurvey <- 100
min_year <- min(year(flow_405232$date_formatted))
max_year <- max(year(flow_405232$date_formatted))
survey_dates <- ymd(
  paste(
    sample((min_year + 1L):(max_year - 1L), size = nsurvey, replace = TRUE),
    sample(4:6, size = nsurvey, replace = TRUE),
    sample(1:30, size = nsurvey, replace = TRUE),
    sep = "-"
  )
)

# calculate annual daily flow average but truncate data points after the survey date
daily_flow <- calculate(
  value = flow_405232$value_stream_discharge_mld,
  date = flow_405232$date_formatted,
  resolution = survey(season = 7:18, lag = 0, end = survey_dates),
  fun = median,
  na.rm = TRUE
)
```

Note that truncation provides one output per `start` or `end` date. This can be a useful trick when attempting to collate metrics for a random collection of dates (even if these aren't truncated per se) because it will save a reconfiguration/join step after standard metric calculations. Note that the use of `start` and `end` dates automatically accounts for duplicated dates to avoid excessive computation in cases where `start` or `end` dates are repeated many times.

## Working with many variables or systems

The above examples might get a bit tedious if you're working with data from many systems and with many variables. This section includes a few examples to show how the `dplyr` package can be used to simplify calculations. This is currently a bit tedious but the upcoming realse of `dplyr` promises some changes that will make this much easier. Note: it is likely that the current version of `dplyr` in R 4.1.0 has simplified the examples below.

```{r calculate-grouped}
# data from multiple sites but only one variable
flow_by_site <- flow_wide %>%
  group_by(site_name, site_code) %>%
  do(
    calculate(
      value = .$value_stream_discharge_mld,
      date = .$date_formatted,
      resolution = survey(season = 9:11),
      na.rm = TRUE
    )
  ) %>%
  ungroup

# we can put this in a wider format if we want (each site has its own column)
flow_by_site_wide <- flow_by_site %>%
  pivot_wider(id_cols = date,
              names_from = site_code,
              values_from = metric)

# data from multiple variables and sites
variable_by_site <- flow_data %>%
  group_by(site_name, site_code, variable_name) %>%
  do(
    calculate(
      value = .$value,
      date = .$date_formatted,
      resolution = survey(season = 9:11),
      na.rm = TRUE
    )
  ) %>%
  ungroup

# we can put this in a wider format if we want (each variable has its own column)
variable_by_site_wide <- variable_by_site %>%
  pivot_wider(id_cols = c(site_name, site_code, date),
              names_from = variable_name,
              values_from = metric)

# or give each site and variable its own column
variable_by_site_wider <- variable_by_site %>%
  pivot_wider(id_cols = date,
              names_from = c(variable_name, site_code),
              values_from = metric)

# the following won't work now but is touted to work in dplyr v.1.0.0 and
#   seems much cleaner
# flow_data %>%
#   filter(variable_name == "stream_discharge_mld") %>%
#   group_by(site_name) %>%
#   summarise(
#     spring_flow = calculate(value, date_formatted, survey(season = 9:11), na.rm = TRUE)$metric,
#     summer_flow = calculate(value, date_formatted, survey(season = 12:3), na.rm = TRUE)$metric
#   )
```
